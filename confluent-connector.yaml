apiVersion: platform.confluent.io/v1beta1
kind: Connector
metadata:
  name: debezium-postgresql-connector
  namespace: confluent
spec:
  class: io.debezium.connector.postgresql.PostgresConnector
  taskMax: 2
  configs:
    connector.class: "io.debezium.connector.postgresql.PostgresConnector"
    tasks.max: "2"
    database.hostname: "postgresql.default.svc.cluster.local"
    database.dbname: "postgres"
    database.port: "5432"
    database.user: "postgres"
    database.password: "0B9JDFxi5E"
    database.config.output.plugin: "pgoutput"
    key.converter: "org.apache.kafka.connect.storage.StringConverter"
    key.converter.schemas.enable: "false"
    value.converter: "org.apache.kafka.connect.json.JsonConverter"
    value.converter.schemas.enable: "false"
    table.include.list: "public.user"
    topic.prefix: "integrate"
    topic.creation.groups: "public"
    topic.creation.default.replication.factor: "2"
    topic.creation.default.partitions: "2"
    topic.creation.default.cleanup.policy: "delete"
    topic.creation.default.compression.type: "producer"
    topic.creation.default.retention.ms: "25920000"
    topic.creation.public.include: "integrate\\.public\\.(.*)"
    topic.creation.public.cleanup.policy: "update"
    message.key.columns: "postgres.public.user:id;"
    plugin.name: "pgoutput"
    transforms: "unwrap,createKey,extractId"
    transforms.unwrap.type: "io.debezium.transforms.ExtractNewRecordState"
    transforms.unwrap.drop.tombstones: "true"
    transforms.unwrap.delete.handling.mode: "rewrite"
    transforms.createKey.type: "org.apache.kafka.connect.transforms.ValueToKey"
    transforms.createKey.fields: "id"
    transforms.extractId.type: "org.apache.kafka.connect.transforms.ExtractField$Key"
    transforms.extractId.field: "id"
    decimal.handling.mode: "string"
    snapshot.mode: "initial"
    slot.name: "debezium_test"
    publication.name: "dbz_publication_test"
    publication.autocreate.mode: "filtered"
    behavior.on.null.values: "delete"